{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP5328 Assignment 1 NMF Algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the datasets using one function\n",
    "def load_data_set(root='../data/CroppedYaleB', reduce=4):\n",
    "    \n",
    "    images, labels = [], []\n",
    "    \n",
    "    for index, f_images in enumerate(os.listdir(root)):\n",
    "       \n",
    "        if not os.path.isdir(os.path.join(root, f_images)):\n",
    "            continue\n",
    "        else:\n",
    "            for fname in os.listdir(os.path.join(root, f_images)):\n",
    "                \n",
    "                #Pass the images:\n",
    "                if fname.endswith('Ambient.pgm'):\n",
    "                    continue\n",
    "                    \n",
    "                elif fname.endswith('.pgm'):\n",
    "                    \n",
    "                    #Load the images:\n",
    "                    image = Image.open(os.path.join(root, f_images, fname))\n",
    "                    image = image.convert('L')\n",
    "\n",
    "#                     # reduce computation complexity.\n",
    "                    image = image.resize([s//reduce for s in image.size])\n",
    "\n",
    "                    # TODO: preprocessing.\n",
    "\n",
    "                    # convert image to numpy array.\n",
    "                    image = np.asarray(image)\n",
    "                    \n",
    "                    images.append(image)\n",
    "                    labels.append(index)\n",
    "\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YaleB dataset.\n",
    "X1, Y1 = load_data_set(root='../data/CroppedYaleB', reduce=4)\n",
    "\n",
    "# Load Extended ORL dataset.\n",
    "X2, Y2 = load_data_set(root='../data/ORL', reduce=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##salt and pepper noise\n",
    "def salt_pepper_noise(data, p, r, image_size):\n",
    "    \n",
    "    data_copy = copy.deepcopy(data)\n",
    "    data_copy = np.array(data_copy).reshape(data_copy.shape[1], image_size[0], image_size[1])\n",
    "    \n",
    "    NoiseNum=int(p*data_copy.shape[0]*data_copy.shape[1])\n",
    "    NoiseNum_r = int(r*data_copy.shape[0]*data_copy.shape[1])\n",
    "    \n",
    "    #randX for random row and randY for random column\n",
    "    for i in range(NoiseNum):\n",
    "        randX = np.random.randint(0, data_copy.shape[0]-1)\n",
    "        randY = np.random.randint(0, data_copy.shape[1]-1)\n",
    "        \n",
    "        #random.random for a random float integer.\n",
    "        #Randomly take an expected point, half of which may be white point 255, and half may be black point 0\n",
    "        if random.random()<=0.5:           \n",
    "            data_copy[randX,randY]=0        \n",
    "        else:            \n",
    "            data_copy[randX,randY]=255 \n",
    "    \n",
    "    #randomly pick pixels to generate white points\n",
    "    for i in range(NoiseNum_r):\n",
    "        randX = np.random.randint(0, data_copy.shape[0]-1)\n",
    "        randY = np.random.randint(0, data_copy.shape[1]-1)\n",
    "                   \n",
    "        data_copy[randX,randY]=255               \n",
    "    return data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gauss noise\n",
    "def guass_generation(data,image_size, ratio):\n",
    "    \n",
    "    data_guass = copy.deepcopy(data)\n",
    "    \n",
    "    \n",
    "    data_guass = np.array(data_guass).reshape(data_guass.shape[1], image_size[0], image_size[1])\n",
    "    \n",
    "    ##definition of gauss noise\n",
    "    mean = 0\n",
    "    sigma = 3\n",
    "    \n",
    "    for i in range(len(data_guass)):\n",
    "        \n",
    "        guass = np.random.normal(mean, sigma, (image_size[0], image_size[1]))\n",
    "        guass = guass * ratio\n",
    "        data_guass[i] = data_guass[i] + guass\n",
    "        \n",
    "    return data_guass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data sampling\n",
    "\n",
    "def data_sampling(data, label, split):\n",
    "    \n",
    "    data = np.array(data)\n",
    "    \n",
    "    data = data.reshape(-1, len(data))\n",
    "    \n",
    "    n = data.shape[1]\n",
    "    \n",
    "    k = int(n * split)\n",
    "    \n",
    "    temp = np.row_stack((data, label))\n",
    "    \n",
    "    temp = np.random.permutation(temp.T)[0:k].T\n",
    "    \n",
    "    X_s = temp[:-1]\n",
    "    Y_s = temp[-1]\n",
    "    \n",
    "    return X_s, Y_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Yale data--pre-processing\n",
    "image_size = np.array(X1).shape[1], np.array(X1).shape[2]\n",
    "\n",
    "Yale_clean = []\n",
    "Yale_label = []\n",
    "\n",
    "## create subset for noise data\n",
    "\n",
    "Yale_salt_pepper = []\n",
    "Yale_guss = []\n",
    "\n",
    "for i in range(5):\n",
    "    Yale_x_sub, Yale_y_sub = data_sampling(X1, Y1, 0.9)\n",
    "    Yale_clean.append(Yale_x_sub)\n",
    "    Yale_label.append(Yale_y_sub)\n",
    "    \n",
    "    ##salt and pepper noise\n",
    "    Yale_salt_pepper_sub = salt_pepper_noise(Yale_x_sub, 0.1, 0.4, image_size)\n",
    "    Yale_salt_pepper_sub = Yale_salt_pepper_sub.reshape(-1, Yale_salt_pepper_sub.shape[0])\n",
    "    \n",
    "    Yale_salt_pepper.append(Yale_salt_pepper_sub)\n",
    "    \n",
    "    ## guass\n",
    "    \n",
    "    Yale_guass_sub = guass_generation(Yale_x_sub,image_size, ratio = 3)\n",
    "    Yale_guass_sub = Yale_guass_sub.reshape(-1, Yale_guass_sub.shape[0])\n",
    "    \n",
    "    Yale_guss.append(Yale_guass_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORL data--pre-processing\n",
    "image_size = np.array(X2).shape[1], np.array(X2).shape[2]\n",
    "\n",
    "ORL_clean = []\n",
    "ORL_label = []\n",
    "\n",
    "## create subset for noise data\n",
    "\n",
    "ORL_salt_pepper = []\n",
    "ORL_guss = []\n",
    "\n",
    "for i in range(5):\n",
    "    ORL_x_sub, ORL_y_sub = data_sampling(X2, Y2, 0.9)\n",
    "    ORL_clean.append(ORL_x_sub)\n",
    "    ORL_label.append(ORL_y_sub)\n",
    "    \n",
    "    ##salt and pepper noise\n",
    "    ORL_salt_pepper_sub = salt_pepper_noise(ORL_x_sub, 0.1, 0.4, image_size)\n",
    "    ORL_salt_pepper_sub = ORL_salt_pepper_sub.reshape(-1, ORL_salt_pepper_sub.shape[0])\n",
    "    \n",
    "    ORL_salt_pepper.append(ORL_salt_pepper_sub)\n",
    "    \n",
    "    ## guass\n",
    "    \n",
    "    ORL_guass_sub = guass_generation(ORL_x_sub,image_size, ratio = 3)\n",
    "    ORL_guass_sub = ORL_guass_sub.reshape(-1, ORL_guass_sub.shape[0])\n",
    "    \n",
    "    ORL_guss.append(ORL_guass_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple NMF Algorithm Definition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_nmf(X_train, n_rank, small_number = 1e-5, max_iter = 1000):\n",
    "    #Steps：\n",
    "    #1.Randomly find W，H（D，R）\n",
    "    #2.UpdateW，H（D，R）\n",
    "\n",
    "    ##Initialize W，H（D，R）  \n",
    "\n",
    "    W = np.random.random((X_train.shape[0], n_rank))  ##shape[0] for columns\n",
    "    H = np.random.random((n_rank, X_train.shape[1]))  ##shape[1] for rows，reconstitute a new matrix with rank\n",
    "\n",
    "    ##Update- number of iterations, difference value\n",
    "\n",
    "    n_iter = 0\n",
    "    diff = 1\n",
    "\n",
    "\n",
    "    while diff >=small_number and n_iter <=max_iter:\n",
    "        #Update W，H ->Multiplication update rule\n",
    "\n",
    "        H = H * (W.T.dot(X_train)/ W.T.dot(W).dot(H))\n",
    "        W = W * (X_train.dot(H.T) / W.dot(H).dot(H.T))\n",
    "\n",
    "        diff = np.linalg.norm(X_train - W.dot(H)) ** 2\n",
    "        \n",
    "        n_iter += 1\n",
    "\n",
    "    return H,W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train_NMF\n",
    "from tqdm import tqdm\n",
    "\n",
    "def nmf_trainer(train_data_sets, n_components, max_iter = 1000, epoches = 200):\n",
    "    \n",
    "    W_set = []\n",
    "    H_set = []\n",
    "    \n",
    "    num_training = len(train_data_sets)\n",
    "    \n",
    "    for i in tqdm(range(num_training)):\n",
    "        #train the W and H useing simple_nmf() function\n",
    "        W,H = simple_nmf(train_data_sets[i], n_rank = n_components, small_number = 1e-5, max_iter = max_iter)\n",
    "        W_set.append(W)\n",
    "        H_set.append(H)\n",
    "        \n",
    "    return W_set, H_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple NMF Training and Evaluation(RRE, ACC, NMI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation methods--RRE ACC and NMI\n",
    "from collections import Counter\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "\n",
    "## RRE\n",
    "def RRE(X_clean, W, H):\n",
    "    \n",
    "    ## RRE = ||V - WH||/||V||\n",
    "    return np.linalg.norm(X_clean - W.dot(H)) / np.linalg.norm(X_clean)\n",
    "\n",
    "\n",
    "def assign_cluster_label(X, Y):\n",
    "    kmeans = KMeans(n_clusters=len(set(Y))).fit(X)\n",
    "    Y_pred = np.zeros(Y.shape)\n",
    "    for i in set(kmeans.labels_):\n",
    "        ind = kmeans.labels_ == i\n",
    "        Y_pred[ind] = Counter(Y[ind]).most_common(1)[0][0] # assign label.\n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:09<00:00, 73.92s/it]\n"
     ]
    }
   ],
   "source": [
    "## Yale_salt_pepper\n",
    "\n",
    "W_Yale_salt_pepper, H_Yale_salt_pepper = nmf_trainer(Yale_salt_pepper, n_components = len(set(Y1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ACC of Yale_salt_pepper nosie is 0.0821\n",
      "Mean NMI of Yale_salt_pepper nosie is 0.0717\n",
      "Mean RRE of Yale_salt_pepper nosie is 1.1999\n"
     ]
    }
   ],
   "source": [
    "##RRE, ACC and NMI for Yale salt-pepper noise for simple NMF\n",
    "rre_Yale_salt_pepper = []\n",
    "acc_Yale_salt_pepper = []\n",
    "nmi_Yale_salt_pepper = []\n",
    "for i in range(5):\n",
    "        H = W_Yale_salt_pepper[i]\n",
    "        W = H_Yale_salt_pepper[i]\n",
    "        error = RRE(Yale_clean[i], W, H)\n",
    "        Y_pred = assign_cluster_label(H.T, Yale_y_sub)\n",
    "        acc = accuracy_score(Yale_y_sub, Y_pred)\n",
    "        nmi = normalized_mutual_info_score(Yale_y_sub, Y_pred,average_method='arithmetic')\n",
    "        acc_Yale_salt_pepper.append(acc)\n",
    "        nmi_Yale_salt_pepper.append(nmi)\n",
    "        rre_Yale_salt_pepper.append(error)\n",
    "        \n",
    "print(\"Mean ACC of Yale_salt_pepper nosie is %.4f\" %(np.mean(acc_Yale_salt_pepper)))\n",
    "print(\"Mean NMI of Yale_salt_pepper nosie is %.4f\" %(np.mean(nmi_Yale_salt_pepper)))\n",
    "print(\"Mean RRE of Yale_salt_pepper nosie is %.4f\" %(np.mean(rre_Yale_salt_pepper)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:09<00:00, 73.87s/it]\n"
     ]
    }
   ],
   "source": [
    "#yale gaussian\n",
    "W_Yale_guass, H_Yale_guass = nmf_trainer(Yale_guss, n_components = len(set(Y1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RRE of guass nosie is 0.3448\n",
      "Mean ACC of guass nosie is 0.1115\n",
      "Mean NMI of guass nosie is 0.1544\n"
     ]
    }
   ],
   "source": [
    "##RRE, ACC and NMI for Yale gauss noise\n",
    "rre_yale_guass = []\n",
    "acc_Yale_guass = []\n",
    "nmi_Yale_guass = []\n",
    "for i in range(5):\n",
    "        H = W_Yale_guass[i]\n",
    "        W = H_Yale_guass[i]\n",
    "        error = RRE(Yale_clean[i], W, H)\n",
    "        Y_pred = assign_cluster_label(H.T, Yale_y_sub)\n",
    "        acc = accuracy_score(Yale_y_sub, Y_pred)\n",
    "        nmi = normalized_mutual_info_score(Yale_y_sub, Y_pred,average_method='arithmetic')\n",
    "        acc_Yale_guass.append(acc)\n",
    "        nmi_Yale_guass.append(nmi)\n",
    "        rre_yale_guass.append(error)\n",
    "        \n",
    "print(\"Mean RRE of guass nosie is %.4f\" %(np.mean(rre_yale_guass)))\n",
    "print(\"Mean ACC of guass nosie is %.4f\" %(np.mean(acc_Yale_guass)))\n",
    "print(\"Mean NMI of guass nosie is %.4f\" %(np.mean(nmi_Yale_guass)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:50<00:00, 10.14s/it]\n"
     ]
    }
   ],
   "source": [
    "#orl salt-pepper\n",
    "W_ORL_salt_pepper, H_ORL_salt_pepper = nmf_trainer(ORL_salt_pepper, n_components = len(set(Y2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RRE of ORL_sale_pepper nosie is 0.7420\n",
      "Mean ACC of ORL_sale_pepper nosie is 0.1722\n",
      "Mean NMI of ORL_sale_pepper nosie is 0.3664\n"
     ]
    }
   ],
   "source": [
    "##RRE, ACC and NMI for ORL salt-pepper noise\n",
    "rre_ORL_salt_pepper = []\n",
    "acc_ORL_salt_pepper = []\n",
    "nmi_ORL_salt_pepper = []\n",
    "for i in range(5):\n",
    "        H = W_ORL_salt_pepper[i]\n",
    "        W = H_ORL_salt_pepper[i]\n",
    "        error = RRE(ORL_clean[i], W, H)\n",
    "        Y_pred = assign_cluster_label(H.T, ORL_y_sub)\n",
    "        acc = accuracy_score(ORL_y_sub, Y_pred)\n",
    "        nmi = normalized_mutual_info_score(ORL_y_sub, Y_pred,average_method='arithmetic')\n",
    "        acc_ORL_salt_pepper.append(acc)\n",
    "        nmi_ORL_salt_pepper.append(nmi)\n",
    "        rre_ORL_salt_pepper.append(error)\n",
    "        \n",
    "print(\"Mean RRE of ORL_sale_pepper nosie is %.4f\" %(np.mean(rre_ORL_salt_pepper)))       \n",
    "print(\"Mean ACC of ORL_sale_pepper nosie is %.4f\" %(np.mean(acc_ORL_salt_pepper)))\n",
    "print(\"Mean NMI of ORL_sale_pepper nosie is %.4f\" %(np.mean(nmi_ORL_salt_pepper)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:49<00:00,  9.87s/it]\n"
     ]
    }
   ],
   "source": [
    "#orl gauss\n",
    "W_ORL_guass, H_ORL_guass = nmf_trainer(ORL_guss, n_components = len(set(Y2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RRE of ORL guass nosie is 0.1408\n",
      "Mean ACC of ORL guass nosie is 0.2206\n",
      "Mean NMI of ORL guass nosie is 0.4255\n"
     ]
    }
   ],
   "source": [
    "##RRE, ACC and NMI for ORL gauss noise\n",
    "rre_ORL_guass = []\n",
    "acc_ORL_guass = []\n",
    "nmi_ORL_guass = []\n",
    "for i in range(5):\n",
    "        H = W_ORL_guass[i]\n",
    "        W = H_ORL_guass[i]\n",
    "        error = RRE(ORL_clean[i], W, H)\n",
    "        Y_pred = assign_cluster_label(H.T, ORL_y_sub)\n",
    "        acc = accuracy_score(ORL_y_sub, Y_pred)\n",
    "        nmi = normalized_mutual_info_score(ORL_y_sub, Y_pred,average_method='arithmetic')\n",
    "        acc_ORL_guass.append(acc)\n",
    "        nmi_ORL_guass.append(nmi)\n",
    "        rre_ORL_guass.append(error)\n",
    "        \n",
    "print(\"Mean RRE of ORL guass nosie is %.4f\" %(np.mean(rre_ORL_guass)))\n",
    "print(\"Mean ACC of ORL guass nosie is %.4f\" %(np.mean(acc_ORL_guass)))\n",
    "print(\"Mean NMI of ORL guass nosie is %.4f\" %(np.mean(nmi_ORL_guass)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2,1 norm Based NMF Algorithm Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## L2,1 norm NMF\n",
    "##cited from https://github.com/jasoncoding13/nmf/tree/master/nmf\n",
    "TOL = 1e-5\n",
    "\n",
    "  \n",
    "def random_init(n_components, X):\n",
    "    \"\"\"initialize dictionary and representation by random positive number.\n",
    "    Args\n",
    "        n_components: int.\n",
    "        X: array with shape of [feature size, sample size].\n",
    "    Rets\n",
    "        D: initialized array with shape of [feature size, n_components].\n",
    "        R: initialized array with shape of [n_components, sample size].\n",
    "    \"\"\"\n",
    "    n_features, n_samples = X.shape\n",
    "    avg = np.sqrt(X.mean() / n_components)\n",
    "    rng = np.random.RandomState(13)\n",
    "    D = avg * rng.randn(n_features, n_components)\n",
    "    R = avg * rng.randn(n_components, n_samples)\n",
    "    np.abs(D, out=D)\n",
    "    np.abs(R, out=R)\n",
    "    return D, R\n",
    "\n",
    "class BaseNMF():\n",
    "    \"\"\"Base Class\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            n_components,\n",
    "            init,\n",
    "            tol,\n",
    "            max_iter,\n",
    "            skip_iter):\n",
    "        self.n_components = n_components\n",
    "        self.init = init\n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "        self.skip_iter = skip_iter\n",
    "\n",
    "    def _compute_loss(self, X, D, R):\n",
    "        return None\n",
    "\n",
    "    def _update(self, X, D, R):\n",
    "        return None\n",
    "\n",
    "    def _init(self, X):\n",
    "        if self.init == 'random':\n",
    "            D, R = random_init(self.n_components, X)\n",
    "        return D, R\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        Args\n",
    "            X: array with shape of [feature size, sample size].\n",
    "        Rets\n",
    "            D: array with shape of [feature size, n_components].\n",
    "            R: array with shape of [n_components, sample size].\n",
    "        \"\"\"\n",
    "        D, R = self._init(X)\n",
    "        losses = [self._compute_loss(X, D, R)]\n",
    "        for iter_ in range(self.max_iter):\n",
    "            D, R = self._update(X, D, R)\n",
    "            # check converagence\n",
    "            if iter_ % self.skip_iter == 0:\n",
    "                losses.append(self._compute_loss(X, D, R))\n",
    "                criterion = abs(losses[-1] - losses[-2]) / losses[-2]\n",
    "                #print('iter-{:>4}, criterion-{:0<10.5}, {:>13}'.format(iter_, criterion, losses[-1]))\n",
    "                if criterion < TOL:\n",
    "                    break\n",
    "        return D, R\n",
    "    \n",
    "    \n",
    "class WeightedNMF(BaseNMF):\n",
    "    def __init__(\n",
    "            self,\n",
    "            n_components,\n",
    "            init='random',\n",
    "            tol=1e-5,\n",
    "            max_iter=1000,\n",
    "            skip_iter=10):\n",
    "        super().__init__(n_components, init, tol, max_iter, skip_iter)\n",
    "\n",
    "    def _compute_loss(self, X, D, R):\n",
    "        return None\n",
    "\n",
    "    def _update_weight(self, X, D, R):\n",
    "        return None\n",
    "\n",
    "    def _update(self, X, D, R):\n",
    "        # update W\n",
    "        W = self._update_weight(X, D, R)\n",
    "        # update D\n",
    "        denominator_D = (W * D.dot(R)).dot(R.T)\n",
    "        denominator_D[denominator_D == 0] = np.finfo(np.float32).eps\n",
    "        D = D * ((W * X).dot(R.T)) / denominator_D\n",
    "        # update R\n",
    "        denominator_R = D.T.dot(W * D.dot(R))\n",
    "        denominator_R[denominator_R == 0] = np.finfo(np.float32).eps\n",
    "        R = R * (D.T.dot(W * X)) / denominator_R\n",
    "        return D, R\n",
    "    \n",
    "  \n",
    "    \n",
    "class L21NMF(WeightedNMF):\n",
    "    \"\"\"L21-NMF\n",
    "    \"\"\"\n",
    "    def _compute_loss(self, X, D, R):\n",
    "        return np.sum(np.sqrt(np.sum(np.square(X - D.dot(R)), axis=0)))\n",
    "\n",
    "    def _update_weight(self, X, D, R):\n",
    "        return 1 / np.sqrt(np.sum(np.square(X - D.dot(R)), axis=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2,1 norm Based NMF Training and Evaluation(RRE, ACC, NMI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [10:57<00:00, 131.54s/it]\n"
     ]
    }
   ],
   "source": [
    "#Yale Salt-Pepper\n",
    "model = L21NMF(n_components = len(set(Y1)))\n",
    "Ws = []\n",
    "Hs = []\n",
    "for i in tqdm(range(5)):\n",
    "    W,H = model.fit(Yale_salt_pepper[i])\n",
    "    Ws.append(W)\n",
    "    Hs.append(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RRE of L21 Yale salt_pepper nosie is 1.1983\n",
      "Mean ACC of L21 Yale salt_pepper nosie is 0.0817\n",
      "Mean NMI of L21 Yale salt_pepper nosie is 0.0753\n"
     ]
    }
   ],
   "source": [
    "##RRE, ACC and NMI for Yale salt-pepper noise in l21\n",
    "rre_Yale_L21_salt_pepper = []\n",
    "acc_Yale_L21_salt_pepper = []\n",
    "nmi_Yale_L21_salt_pepper = []\n",
    "for i in range(5):\n",
    "        W = Ws[i]\n",
    "        H = Hs[i]\n",
    "        error = RRE(Yale_clean[i], W, H)\n",
    "        Y_pred = assign_cluster_label(H.T, Yale_y_sub)\n",
    "        acc = accuracy_score(Yale_y_sub, Y_pred)\n",
    "        nmi = normalized_mutual_info_score(Yale_y_sub, Y_pred,average_method='arithmetic')\n",
    "        acc_Yale_L21_salt_pepper.append(acc)\n",
    "        nmi_Yale_L21_salt_pepper.append(nmi)\n",
    "        rre_Yale_L21_salt_pepper.append(error)\n",
    "\n",
    "print(\"Mean RRE of L21 Yale salt_pepper nosie is %.4f\" %(np.mean(rre_Yale_L21_salt_pepper)))\n",
    "print(\"Mean ACC of L21 Yale salt_pepper nosie is %.4f\" %(np.mean(acc_Yale_L21_salt_pepper)))\n",
    "print(\"Mean NMI of L21 Yale salt_pepper nosie is %.4f\" %(np.mean(nmi_Yale_L21_salt_pepper)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [11:18<00:00, 135.63s/it]\n"
     ]
    }
   ],
   "source": [
    "#Yale gaussian\n",
    "model = L21NMF(n_components = len(set(Y1)))\n",
    "Ws = []\n",
    "Hs = []\n",
    "for i in tqdm(range(5)):\n",
    "    W,H = model.fit(Yale_guss[i])\n",
    "    Ws.append(W)\n",
    "    Hs.append(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RRE of L21 gaussian nosie is 0.3448\n",
      "Mean ACC of L21 gaussian nosie is 0.1120\n",
      "Mean NMI of L21 gaussian nosie is 0.1565\n"
     ]
    }
   ],
   "source": [
    "##RRE, ACC and NMI for Yale gauss noise in l21\n",
    "rre_Yale_L21_gua = []\n",
    "acc_Yale_L21_gua = []\n",
    "nmi_Yale_L21_gua = []\n",
    "for i in range(5):\n",
    "        W = Ws[i]\n",
    "        H = Hs[i]\n",
    "        error = RRE(Yale_clean[i], W, H)\n",
    "        Y_pred = assign_cluster_label(H.T, Yale_y_sub)\n",
    "        acc = accuracy_score(Yale_y_sub, Y_pred)\n",
    "        nmi = normalized_mutual_info_score(Yale_y_sub, Y_pred,average_method='arithmetic')\n",
    "        acc_Yale_L21_gua.append(acc)\n",
    "        nmi_Yale_L21_gua.append(nmi)\n",
    "        rre_Yale_L21_gua.append(error)\n",
    "        \n",
    "print(\"Mean RRE of L21 gaussian nosie is %.4f\" %(np.mean(rre_Yale_L21_gua)))\n",
    "print(\"Mean ACC of L21 gaussian nosie is %.4f\" %(np.mean(acc_Yale_L21_gua)))\n",
    "print(\"Mean NMI of L21 gaussian nosie is %.4f\" %(np.mean(nmi_Yale_L21_gua)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:46<00:00, 21.35s/it]\n"
     ]
    }
   ],
   "source": [
    "#ORL salt-pepper\n",
    "model = L21NMF(n_components = len(set(Y2)))\n",
    "Ws = []\n",
    "Hs = []\n",
    "for i in tqdm(range(5)):\n",
    "    W,H = model.fit(ORL_salt_pepper[i])\n",
    "    Ws.append(W)\n",
    "    Hs.append(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RRE of L21 ORL salt pepper nosie is 0.7421\n",
      "Mean ACC of L21 ORL salt pepper nosie is 0.1783\n",
      "Mean NMI of L21 ORL salt pepper nosie is 0.3782\n"
     ]
    }
   ],
   "source": [
    "##RRE, ACC and NMI for ORL salt-pepper noise in l21\n",
    "rre_ORL_L21_salt_pepper = []\n",
    "acc_ORL_L21_salt_pepper = []\n",
    "nmi_ORL_L21_salt_pepper = []\n",
    "for i in range(5):\n",
    "        W = Ws[i]\n",
    "        H = Hs[i]\n",
    "        error = RRE(ORL_clean[i], W, H)\n",
    "        Y_pred = assign_cluster_label(H.T, ORL_y_sub)\n",
    "        acc = accuracy_score(ORL_y_sub, Y_pred)\n",
    "        nmi = normalized_mutual_info_score(ORL_y_sub, Y_pred,average_method='arithmetic')\n",
    "        acc_ORL_L21_salt_pepper.append(acc)\n",
    "        nmi_ORL_L21_salt_pepper.append(nmi)\n",
    "        rre_ORL_L21_salt_pepper.append(error)\n",
    "        \n",
    "print(\"Mean RRE of L21 ORL salt pepper nosie is %.4f\" %(np.mean(rre_ORL_L21_salt_pepper)))\n",
    "print(\"Mean ACC of L21 ORL salt pepper nosie is %.4f\" %(np.mean(acc_ORL_L21_salt_pepper)))\n",
    "print(\"Mean NMI of L21 ORL salt pepper nosie is %.4f\" %(np.mean(nmi_ORL_L21_salt_pepper)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:35<00:00, 19.11s/it]\n"
     ]
    }
   ],
   "source": [
    "#ORL gaussian\n",
    "model = L21NMF(n_components = len(set(Y2)))\n",
    "Ws = []\n",
    "Hs = []\n",
    "for i in tqdm(range(5)):\n",
    "    W,H = model.fit(ORL_guss[i])\n",
    "    Ws.append(W)\n",
    "    Hs.append(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RRE of guassian nosie is 0.1413\n",
      "Mean ACC of guassian nosie is 0.2306\n",
      "Mean NMI of guassian nosie is 0.4363\n"
     ]
    }
   ],
   "source": [
    "##RRE, ACC and NMI for ORL gauss noise in l21\n",
    "rre_ORL_L21_gua = []\n",
    "acc_ORL_L21_gua = []\n",
    "nmi_ORL_L21_gua = []\n",
    "for i in range(5):\n",
    "        W = Ws[i]\n",
    "        H = Hs[i]\n",
    "        error = RRE(ORL_clean[i], W, H)\n",
    "        Y_pred = assign_cluster_label(H.T, ORL_y_sub)\n",
    "        acc = accuracy_score(ORL_y_sub, Y_pred)\n",
    "        nmi = normalized_mutual_info_score(ORL_y_sub, Y_pred,average_method='arithmetic')\n",
    "        acc_ORL_L21_gua.append(acc)\n",
    "        nmi_ORL_L21_gua.append(nmi)\n",
    "        rre_ORL_L21_gua.append(error)\n",
    "        \n",
    "print(\"Mean RRE of guassian nosie is %.4f\" %(np.mean(rre_ORL_L21_gua)))\n",
    "print(\"Mean ACC of guassian nosie is %.4f\" %(np.mean(acc_ORL_L21_gua)))\n",
    "print(\"Mean NMI of guassian nosie is %.4f\" %(np.mean(nmi_ORL_L21_gua)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
